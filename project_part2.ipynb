{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# NLP Project 2: Comparative Analysis of Summarization Models\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this segment of the research project, we delve into the realm of automated text summarization, focusing on evaluating and comparing the performance of various state-of-the-art language models. The central objective is to understand how different models behave under varying input conditions and to analyze the nuances in their summarization capabilities.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "### Dataset Generation\n",
    "\n",
    "To facilitate a comprehensive and unbiased comparison, a specialized program has been developed. This program is capable of generating new datasets of summaries, based on a set truncation length. This ensures a level playing field for all models under scrutiny, and enables us to compare the affect that input length has on the quality of summaries.\n",
    "\n",
    "The program utilizes an apiEndpoint factory that implements an interface that ensures all api endpoints operate under indentical logical conditions. At runtime, the program queries the user for a prompt, a videoId, and a caption type. This is then passed off to each api endpoint sequentially ensuring identical inputs to each model used.\n",
    "\n",
    "I plan to use chatbots in the final project, simply by supplying the prompt \"please summarize the text {captions}\" and again, supplying identical captions through the api endpoint factory. However, I cold not get my openai account working before the deadline. (this video tripped up most of the models, although some did mention the main points at the end of the summary)\n",
    "\n",
    "Link to github for the dataset generator (and specifically to the file I generated the datasets with): https://github.com/TheMaxta/summaryFactory/blob/main/runAllModels.js\n",
    "\n",
    "### Prompts used\n",
    "\n",
    "For summary models: None, they are all passed identical transcripts and already know how to handle the text.\n",
    "\n",
    "For Chatbots: None, I tried multiple and they all crashed at runtime.\n",
    "\n",
    "\n",
    "### Models for Comparison\n",
    "\n",
    "The models included in this analysis are:\n",
    "\n",
    "- **GPT-4:** An advanced language model known for its versatility and depth in understanding context.\n",
    "- **BART:** A transformer-based model designed for sequence-to-sequence tasks, excelling in summarization.\n",
    "- **Pegasus:** Specifically fine-tuned for abstractive text summarization, known for generating more coherent summaries.\n",
    "- **Text Summarization Model:** A general model for summarization tasks.\n",
    "- **LedLargeBookSummarization:** A model tailored for summarizing longer texts, such as books.\n",
    "\n",
    "\n",
    "\n",
    "### Complications Encountered\n",
    "\n",
    "- **Data Preparation:** Preparing the datasets for each model was a challenge, as each model had different input requirements and sensitivities. \n",
    "\n",
    "- **Interpreting Results:** Deciphering the subtleties in the summaries generated by each model and comparing them objectively proved to be a complex task, given the subjective nature of summarization quality.\n",
    "\n",
    "- **Consistency in Evaluation:** Establishing a consistent and fair framework for evaluating the performance of each model was challenging. I had to do a lot of guess work for this project, and plan to implement a more robust benchmarking technique for future project like the ones seen on model pages on hugging face.\n",
    "\n",
    "### Experiment Design\n",
    "\n",
    "The experiment will be conducted as follows:\n",
    "\n",
    "1. **Input Preparation:** Identical input content will be fed into each language model. This ensures fairness and consistency in the comparison.\n",
    "2. **Truncation Variations:** The program will generate datasets for inputs with lengths of 500, 1000, and 1500 characters. This is to observe how the models perform under different input length constraints.\n",
    "3. **Quality Assessment:** The quality of the generated summaries will be evaluated. This will involve assessing coherence, relevancy, and conciseness.\n",
    "4. **Comparative Analysis:** Observations will be made on how the summaries vary across different models and input lengths.\n",
    "\n",
    "\n",
    "## Objectives for Summaries:\n",
    "  - We want to use summary to save time\n",
    "  - Get the general points brought up in the video. \n",
    "  - A great summary logically orders all main points.\n",
    "  - Summary should stay objective without directly replicating the words in the video.\n",
    "  - The best summary model can understand the underlying representations of the text really well, and extracts pionts and then exrapolates to it's own language.\n",
    "\n",
    "### Notes on Models post dataset review:\n",
    "\n",
    "#### GPT-4:\n",
    "- Unfortunately, the model broke before I could submit the assignment. I ran out of API usage and OpenAi never reinstated my api key, so I couldn't generate summaries\n",
    "\n",
    "#### BART:\n",
    "- Bart does seem to perform really well on longer input lengths, but almost always replicates the words used in the video without extrapolating at all. \n",
    "- Bart can not handle large inputs, and this is a large reason that this analysis does not extend to past 1500 characters of transcript data.\n",
    "- Based on the responses given, Bart tends to do more cutting down on filler words rather than understanding the underlying meaning of the text. (However it does extract main points well)\n",
    "- Bart seems to be a great tool to narrow down on the main points in text.\n",
    "- The model was trained for the purpose of transcript summarization, so needless to say, this model performs pretty well on transcripts.\n",
    "\n",
    "\n",
    "#### Pegasus:\n",
    "- Pegasus is primarily trained on summarization specific data sets and that could determine why it's output is so different compared to the other models in use. (they were trained on a wider range of data)\n",
    "- Pegasus greatly condenses giant swathes of text down to one or two main points presented in the text. It seems to do a really good job of getting the MAIN point, but is not very useful for detailed summarization.\n",
    "- Certain content is not summarized very well. if the content brings up an analogy, like it did in the dataset for a video titled \"Vectoring Words (Word Embeddings) - Computerphile\" the speaker uses an analogy to break down the subject. The main point is not extracted by pegasus, instead we get a weird nonsensical sentence repeating cat and dog over and over. Likely because the analogy is about a cat and a dog, but that just shows how this model likely identifies repition a little too hastily.\n",
    "\n",
    "#### Text Summarization (falcon):\n",
    "- In some cases, the Falcon Text Summarization model does the best job at retaining the actual names and factual details in videos. Where other videos cut out important details like the mathematical concepts discussed in the video, this model kept that information in the summary.\n",
    "- Almost all summaries replicate the speaking voice / personality of the orator from the video, almost to an annoying degree, possibly reducing the quality of summary. While I have noticed longer character lengths do less of the replication of the personality of the speaker. \n",
    "\n",
    "#### LedLargeBookSummarization:\n",
    "- This model also broke. It worked in testing, but I could not get it to run as a batch job. \n",
    "\n",
    "### In conclusion:\n",
    "- None of the models are capable of extrapolating to their own voice, rather, they cut out filler words really well and understand some of the main points (leave this to gpt4)\n",
    "- Almost all of the models very clearly identify repition in keywords and phrases and apply a higher weight to those words appearing in the summary, while some of the better performing models are still able to gather some of the topics despite the presence of repition. \n",
    "- In general, these models still perform quite well for their size and the fact that they are free and easy to access. They do a good job of cutting down on filler words, however, weird nuances will trip them up and you will get weird outputs.\n",
    "- All of these models utilize transformers, and almost all (except for text summarization [falcon]) are encoder-decoder models, which heavily rely on attention mechanisms to learn the underlying meaning / representations of words. These models use embeddings, positional encodings, and attention mechanisms to process their input / output, and that is likely why many of them generate similar results with identical inputs. However, these models are trained on various datasets and that likely has a big affect on the results\n",
    "\n",
    "### Changes Observed:\n",
    "\n",
    "#### Between 500 and 1000 Characters:\n",
    "- Lots of summaries cut off randomly when only supplied 500 characters, and there is a little more explanation at 1000 characters.\n",
    "- However, these responses from the model are better than you might expect, because often times the main topics of a video are brought up at the start. This is likely something that many of the models identify while training.\n",
    "- \n",
    "\n",
    "#### Between 500 and 1500 Characters:\n",
    "- There is usually much more detail at 1500 characters.\n",
    "- The first part of the summary is only slightly changed, while the summaries are typically much longer when supplied more input characters. But this does not happen every time.\n",
    "- In one example, (fromt Bart) the 500 character summary is basically just an intro, but at 1500 characters we are introduced to the main talking points rather than the intro. However, this is one case and later on the same model repeats the introduction in the long form version, and just includes a couple additional details.\n",
    "- \n",
    "\n",
    "# NLP Summarization Models Overview\n",
    "\n",
    "An overview of various state-of-the-art models used in natural language processing for text summarization tasks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GPT-4\n",
    "- **Type:** Neural Network (Transformers)\n",
    "- **Architecture:** Decoder-only architecture\n",
    "- **Mechanism:** \n",
    "  - Utilizes a modified version of the transformer architecture, fundamentally based on self-attention mechanisms.\n",
    "  - Capable of understanding and generating human-like text by predicting the next word in a sequence.\n",
    "- **Datasets:** \n",
    "  - Trained on a diverse range of internet text.\n",
    "  - Specific datasets are not publicly disclosed, but it includes books, websites, and other texts available online up to its training cut-off in 2021.\n",
    "\n",
    "  \n",
    "## BART (Bidirectional and Auto-Regressive Transformers)\n",
    "\n",
    "- **Type:** Neural Network (Transformers)\n",
    "- **Architecture:** Encoder-Decoder architecture\n",
    "- **Mechanism:** \n",
    "  - Trained by corrupting text with an arbitrary noising function and learning to reconstruct the original text.\n",
    "  - Combines bidirectional context in the encoder with autoregressive capabilities in the decoder.\n",
    "- **Datasets:** \n",
    "  - Primarily trained on large-scale corpora like BookCorpus and English Wikipedia.\n",
    "  - Additional training on diverse text sources for a well-rounded language understanding.\n",
    "\n",
    "## Pegasus (Pre-training with Extracted Gap-sentences for Abstractive SUmmarization Sequence-to-sequence models)\n",
    "\n",
    "- **Type:** Neural Network (Transformers)\n",
    "- **Architecture:** Encoder-Decoder architecture\n",
    "- **Mechanism:** \n",
    "  - Specifically designed for abstractive text summarization.\n",
    "  - Uses a novel pre-training objective called \"gap sentences generation\", aligning closely with the summarization task.\n",
    "- **Datasets:** \n",
    "  - Utilizes large-scale datasets specifically tailored for summarization, such as news article datasets (CNN/DailyMail, XSum) and web sources.\n",
    "  - Designed to excel in summarization by training on text where summaries are naturally occurring.\n",
    "\n",
    "## Text Summarization Model\n",
    "\n",
    "- **Type:** Likely Neural Network (Transformers)\n",
    "- **Architecture:** Encoder-Decoder or Decoder-only (varies)\n",
    "- **Mechanism:** \n",
    "  - Typically uses transformer-based architectures with attention mechanisms.\n",
    "  - Can vary between extractive (selecting parts of the original text) or abstractive (rewriting content in a condensed form) summarization.\n",
    "- **Datasets:** \n",
    "  - The exact datasets can vary depending on the specific implementation.\n",
    "  - Often trained on standard summarization datasets like CNN/DailyMail, XSum, or large-scale internet text corpora.\n",
    "\n",
    "## LedLargeBookSummarization\n",
    "\n",
    "- **Type:** Neural Network (Transformers)\n",
    "- **Architecture:** Likely an Encoder-Decoder architecture\n",
    "- **Mechanism:** \n",
    "  - Designed for long-form text summarization, such as books.\n",
    "  - May use techniques like Longformer to handle longer sequences, involving extended attention mechanisms or hierarchical approaches.\n",
    "- **Datasets:** \n",
    "  - Likely trained on extensive literary works and long-form content sources.\n",
    "  - May include datasets consisting of books, scientific papers, and comprehensive reports to handle long-text summarization.\n",
    "\n",
    "---\n",
    "\n",
    "Each model represents a unique approach to handling the complexities of language, tailored for specific tasks in the realm of natural language processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to your .xlsx files\n",
    "xlsx_files = ['./summaries500char.xlsx', './summaries1000char.xlsx', './summaries1500char.xlsx']\n",
    "\n",
    "# Read and display each dataset\n",
    "for file_path in xlsx_files:\n",
    "    # Read the .xlsx file into a DataFrame\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(f\"Displaying data from: {file_path}\")\n",
    "    display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
